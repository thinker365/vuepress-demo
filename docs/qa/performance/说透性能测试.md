[[toc]]
## 为什么每个测试人都要学好性能测试
- 性能测试并不只是要一个结果，更多的是要从部署结构、代码链路、业务上下游等多角度来综合考量。
- 列举几个常见问题
1. 只会使用 JMeter 但执行却不规范。
	- 在性能测试过程中，工具使用不恰当会影响到性能测试的结果。我见过很多因为工具使用不当导致的客户端瓶颈，让处理能力未达到预期的情况。很多测试没能及时发现是工具的原因，导致自己的专业能力备受质疑。
1. 不会制定有效的性能测试目标。
	- 如果不会制定有效的性能测试目标，那测出来的数据也没有什么参考价值，因为你不知道能不能满足上线需求，也不能准确地评估线上风险，做完了性能测试依然留有一大堆问题。
1. 不会定位和分析性能测试结果。
	- 测试脚本得到的数据并不能直接用来分析系统瓶颈，你只有通过监控去观察系统存在的异常点，然后根据异常点来重点监控相关组件，由表及里、层层深入才能找到根本原因。
- 性能测试真正的价值，并不在于你用工具完成了一份报告，而是通过对过程和结果的分析找到症结，帮助团队有效提升产品性能，比如提升了多少 TPS，降低了多少响应时间，节约了多少硬件成本，等等。
## 性能测试全流程需要注意什么
1. 历史访问数据
	历史访问数据，指的是什么类型的用户通过何种终端访问服务的接口次数。作为衡量性能的重要手段，自然是不可或缺的。
	绝大多数公司都会封装平台来采集历史访问数据，如果要看原始的访问日志，Nginx 日志也是一种方式（如下所示）
	```
	120.204.101.238 - - [29/Nov/2020:14:09:22 +0800] "GET /v1/register HTv1TP/1.1" 200 150 "-
	120.204.101.238 - - [29/Nov/2020:14:09:22 +0800] "POST /v1/login HTTP/1.1" 200 36 "-
	120.204.101.238 - - [29/Nov/2020:14:09:22 +0800] "GET /hello/map HTTP/1.1" 200 202 
	...
	```
1. 需求管理
	- 对需求接入和充分的分析能帮助你在测试之前获得更多的信息，也能制定出较为完善的性能测试方案
	- **需求来源**
	- 需求来源其实就是你这次性能测试的目的，调研清楚这个问题能帮助你更有针对性地获取数据，从而制定更为准确的性能目标。
	- **需求分析**
	- 需求分析是在原始数据中提炼出有效的性能参考数据，通过这些数据构建性能测试的模型，再通过模型形成测试步骤。
	- **分析方案**
	- 性能测试方案的目的不仅仅在于让自己知道这次性能测试如何执行，也要让你的项目成员知道这次性能方案，它的执行周期、涉及的成员等，然后再一起评审这次方案中有没有不合理的地方。
1. 性能测试环境管理
	- 一般情况下我们会独立搭建一套，与业务测试环境相隔离，同时也能够在上线之前尽可能暴露一些代码中的问题。
	- 我曾看到过这样一个观点：线下性能环境与生产环境机器配置相差甚大，我们直接在生产上做性能测试就可以了，没有必要在测试环境中做。
	- 环境的配置高低是决定性能结果的一个影响因素，但不是全部因素。能够提前测试、提前暴露 bug，修复 bug 的成本也就越低，所以在线下必须有专门的性能环境，它可以帮助你提前发现内存泄漏、死锁等问题。更何况，这些问题的发现和修复与服务器硬件配置并没有直接联系，如果能够在线下提早用更低的成本解决是一种更优的选择。
	- 如果没有做线下性能测试的情况下直接在生产上测试，对性能中的异常测试、高可用测试可能无法充分执行；同时，修复性能 bug 也需要功能上的回归，这些都增加了过程管理的复杂度。
1. 监控管理
	- 监控是发现性能问题的眼睛，没有监控，性能定位分析也就无从谈起了。监控的核心在于全面和深入。
	- **客户端数据监控**
	- 性能测试中说的客户端一般是指测试机，测试机输出的数据是观察性能好差的关键指标。我推荐 JMeter+InfluxDB+Grafana 的框架，它具备展现直观、数据实时的特点，可以全面地展示监控的数据。
	- **硬件资源监控**
	- 基础硬件资源监控一般包含 CPU、内存、磁盘、网络等，常用的监控方式可以分为命令行监控和可视化监控。
		- **命令行监控**
		- 通过命令的监控我们能够以最直接的方式获取服务器的实时状态。以 Linux 服务器举例，top、vmstat、iostat、iftop 等都是性能监控常用的命令。
		- **可视化监控**
		- 可视化监控相对于命令行监控提供了更为丰富的图表展示，这样的话看起来更直观易懂，适合监控大屏的展示，能够将监控信息传递给项目组成员，但它需要提取数据之后计算，然后再展示，有一定的延迟，不如命令行监控直接。
		- Zabbix、Prometheus+Grafana 等都是可视化监控常用的手段，它们可以把数据持久化，能够调取过往时间轴的历史数据，一般在回溯、汇报、复盘时使用比较多。
	- 不管采用何种方式，在进行硬件监控时，都应该涵盖测试过程中所有的服务器，包括压测机、应用服务器、中间件服务器数据库服务器等。
	- **链路监控**
	- 链路监控是对代码本身的追踪，代码问题常常是问题产生的根因，所以关于代码的监控不可忽视。目前常用的代码链路追踪工具有 SkyWalking、PinPoint、Arthas。
	- **业务规则监控**
	- 业务逻辑报错和用户息息相关并且用户是可以直接感受到的，比如商品库存不足、用户余额不足，它们会直接影响用户的体验。线上出现问题并不少见，重要的是如何第一时间得知并且解决这些问题。所以当出现问题即时发送报警邮件或者短信也是十分必要的，对于业务的监控同样不能忽视。
1. 数据模型建设
	- 数据模型的意义在于沉淀以往的历史数据，通过不同的维度去发现一些规律，我认为这也是性能测试领域中的一种探索方向。通过数据模型的建设，我们可以尝试在不同纬度建立数据之间的联系，从而发现数据间的规律，对未来的数据进行预测。
	- **时间纬度**
	- 一般的电商每年至少有两次大促，618 和双 11。它们一般会详细记录每年总的成交额、网关访问次数、各个服务访问次数等，通过每年的活动力度、广告投放，以及数据团队来预测下次大促的成交金额和网站访问量等，这些数据也会间接帮助性能测试制定目标。
	- **机器纬度**
	- 机器纬度是一个什么概念呢？你可能会认为在线下两台机器测出来接口的处理能力是 100，线上有 10 台等配置的机器，就不用测试了，处理能力直接按照 5 倍去推算。
	- 这其实是默认只要扩充机器系统的处理能力就会倍数增加，事实上是毫无道理的。不过你可以长期记录接口或者服务在性能测试环境的数据和生产环境中，相同场景下的压测数据，再进行长时间地跟踪对比，尝试发现其中是否能够存在一些规律。

1. 技术建设
	- **熟练掌握一门编程语言**
	- 测试很难说一定要掌握哪一种语言，但是熟练地使用一门语言可以帮助你迅速上手其他编程语言。
	- **能够读懂服务端基本架构**
	- 如果你不懂服务端的架构，那基本只能根据你的性能测试工具去编写报告，了解不到更深层次内容。
	- **能够根据性能测试需求，提出系统改造建议**
	- 性能测试与业务测试不太一样：业务测试基本是通过构造测试场景去满足业务规则，而性能测试，尤其是线上全链路性能测试，为了避免造成线上数据污染和影响真实用户访问，往往会改造系统去进行流量隔离和清理。
## JMeter核心概念
1. JMeter优势
	- **开源免费、安装简易、多系统兼容**
	- 相对于 Loadrunner，JMeter 没有版权的困扰，脚本可以在 Windows、Linux、Mac 任意系统间切换，非常简单方便。
	- **丰富的基础插件**
	- 相对于 Locust，JMeter 提供了较多的插件，可以减少重复造轮子的工作。Locust 的基础功能需要写代码实现，更适合定制性较强的测试场景，如游戏类测试，在敏捷化的测试团队中需要考虑到这部分的时间成本问题。
	- **良好的拓展性**
	- 虽然 JMeter 已经有了丰富的基础插件，它本身还是提供了入口进行二次开发，以满足团队定制化的需求。同样，你也可以将 JMeter 平台化，通过平台化的操作来管理 JMeter，增强测试团队的协作性。
1. 线程与循环
	![](~@img/uTools_1656147004105.png)
	![](~@img/uTools_1656147095574.png)
	从两张图的对比中，我们可以看到图 1 和图 2 的区别在于线程数和循环次数，一个是 1 和 10，一个则是 10 和 1。从结果来看，图 1 和图 2 都是发送了 10 个请求，那它们的核心区别是什么呢？
	先来看图 1 的代码演示：
	```javascript
	for(int j=0;j<10;j++) {
	   System.out.println(Thread.currentThread().getName());//打印线程名字
	}
	```
	这段代码我使用线程循环的方式打印运行线程的名字，运行后的内容如下：
	```
	Thread-0
	......
	Thread-0
	Thread-0 //可以看到是基于同一个线程
	```
	再来看图 2 的代码演示：
	```javascript
	for(int i=0;i<10;i++){
		new Thread(new Runnable() {
			public void run() {
				System.out.println(Thread.currentThread().getName());
			}
		}).start();
	} //示意代码
	```
	这段代码我是使用多线程的方式打印正在运行的线程，运行后效果如下：
	```
	Thread-0
	......
	Thread-8
	Thread-9 //不同的线程
	```
	不难看出，循环的方式是基于同一个线程反复进行 10 次操作，而多线程则启动了 10 个不一样的线程，虽然都是向服务器发送了 10 次请求，但这两种方式完成的时间和对系统的压力也完全不一样。
1. Ramp-Up
	- Ramp-Up 其实是一个可选项，如果没有特殊要求，保持默认配置脚本即可。如果填 1，代表在 1 秒内所有设置线程数全部启动。不过这个是理论上的，实际启动时间也依赖于硬件的接受程度。如果硬件跟不上，启动时间自然也会增加。
	- 在有的性能测试场景中，如果你不想在性能测试一开始让服务器的压力过大，希望按照一定的速度增加线程到既定数值，你就可以使用这个选项。比如我想用 10 个线程进行测试，启动速度是每秒 2 个线程，就可以在这里填 5，如下所示：
	![](~@img/uTools_1656147531615.png)

1. 组件和元件的关系
要解释组件首先就要说元件。我们看图 4 中的 HTTP 请求，其实这就是一个实际的元件。同样作为元件的还可以是 JDBC 请求、Java 请求等，这一类元件我们统一称为取样器，也就是组件。我用一个示意图来表示组件和元件的关系：
![](~@img/uTools_1656148280496.png)

1. 组件的作用
	- JMeter 有多种组件，我们重点看下这七类： 配置元件、取样器、定时器、前置处理器、后置处理器、断言、监听器。
	- 配置元件：用于初始化变量，以便采样器使用。类似于框架的配置文件，参数化需要的配置都在配置元件中。
	- 取样器：承担 JMeter 发送请求的核心功能，支持多种请求类型，如 HTTP、FTP、JDBC 等，也可以使用 Java 类型的请求进行自定义编写。
	- 定时器：一般用来指定请求发送的延时策略。在没有定时器的情况下，JMeter 发送请求是不会暂停的。
	- 前置处理器：在进行取样器请求之前执行一些操作，比如生成入参数据。
	- 后置处理器：在取样器请求完成后执行一些操作，通常用于处理响应数据，从中提取需要的值。
	- 断言：主要用于判断取样器请求或对应的响应是否返回了期望的结果。
	- 监听器：监听器可以在 JMeter 执行测试的过程中搜集相关的数据，然后将这些数据在 JMeter 界面上以树、图、报告等形式呈现出来。不过图形化的呈现非常消耗客户端性能，在正式性能测试中并不推荐使用。
1. 组件的顺序
	![](~@img/uTools_1656148451370.png)
	搞懂了组件顺序，你在测试前准备脚本生成参数化数据时，就可以在前置处理器中寻找相关元件；在要提取接口返回的数据，就可以在后置处理器中寻找相关插件，而不是在其他地方寻找数据，浪费时间。

1. 元件作用域
	JMeter 元件除了从上到下的顺序外，有还具备一定的层次结构。
1. 分布式压测
	- 压测就是 JMeter 通过产生大量线程对服务器进行访问产生负载，监听服务器返回结果并进行校验。在大部分情况下，用单台 JMeter 进行性能测试或者自动化测试是可行的，但在多线程运行过程中可能存在性能瓶颈，很多人在排查定位问题时经常会漏掉这一点。
	- 通常，单机的 JMeter 最好将线程数控制在 1000 以内；如果超过了 1000 线程，则建议使用 JMeter 分布式压测，这在一定程度上可以解决 JMeter 客户端自身形成的瓶颈问题。
	- 在分布式 JMeter 架构下，JMeter 使用的是 Master 和 Slave。
	- Master 负责远程控制 Slave（负载机）。分布式通常有多个 JMeter 节点，其中一个节点承担 Master 的作用。Master 通过发送信号控制节点机的启动和停止，并进行收集节点机的数据等操作。
	- Slave 一般也叫负载机，主要是发起线程来访问 target 服务器。一般在 Slave 节点机上先启动代理 jar 包，控制机远程连接，负载机运行脚本后对 Master 回传数据。流程示意图如下：
	- JMeter 的 Master 和 Slave 配置也比较简单。将 JMeter 的 bin 目录下的 jmeter.properties 文件配置：IP 和 Port 是 Slave 机的 IP 以及默认的 1099 端口。如下所示：
	```
	remote_hosts=ip:1099,ip:1099
	```
	- Slave 启动 jar 包之后，默认会启动 1099 端口。Master 配置完成启动后便可以建立和 Slave 连接，从而进行控制和收集等操作。
	- 一般来说，JMeter 分布式压测都是作为缓减客户端瓶颈的重要方式。强调“缓减”，因为在性能测试领域中不存在一种技术手段能够保证永远没有问题。随着公司的体量发展，对性能的要求也是水涨船高。JMeter 自带的分布式压测作为一种缓解客户端性能问题的方式，并不是万能法则。
## JMeter参数化策略
1. 为什么要进行参数化
	- **数据被缓存导致测试结果不准确**
	- 缓存原本是为了让数据访问的速度接近 CPU 的处理速度而设置的临时存储区域，比如 cache。如今缓存的概念变得更广了，很多空间都可以设置客户端缓存、CDN 缓存等等。
	- 当你频繁地请求某一条固定的数据时，这条数据就很容易被缓存，而不是每次都从数据库中去获取，这就可能导致和真实的场景有差别。
	- **流程不能正常执行**
	- 有的情况是，在没有参数化的情况下，会产生大量的业务报错。打个比方，你在测试限购商品抢购，如果用多线程模拟同一个用户操作可能会直接报错，因为在生成订单接口（支付等）都会判断是否是同一个用户。
1. JMeter参数化的实现方式
	- CSV Data Set Config：将参数化的数据放入文件中，参数化读取依赖于文件操作。这样的参数化方式很常用，尤其适用于参数化数据量较多的场景，而且维护比较简单灵活。
	- User Defined Variables：一般来说可以配置脚本中的公共参数，如域名，端口号，不需要随着压测进行动态改变，比较方便环境切换。
	- Function Helper 中的函数：使用函数的方式生成参数，如果你需要随机数、uuid 等都可以使用函数生成。JMeter 还提供了相应的接口给你二次开发，自定义需要的功能。
	- **CSV Data Set Config**
	- CSV Data Set Config 的可配置选项较多，也是目前性能测试参数化时使用最多的插件。
	![](~@img/uTools_1656149250999.png)
	- 文件名：顾名思义，这里填写文件的名字即可。保存参数化数据的文件目录，我这边是将 user.csv 和脚本放置在同一路径下。在这里我要推荐一个小技巧，就是“相对路径”。使用绝对路径，在做脚本迁移时大部分情况下都需要修改。如果你是先在 Windows 或 Mac 机器上修改脚本，再将脚本上传到 Linux 服务器上执行测试的，那你就可以用相对路径，这样就不用频繁修改该选项了。
	- 文件编码：指定文件的编码格式，设置的格式一般需要和文件编码格式一致，大部分情况下保存编码格式为 UTF-8 即可。
	- 变量名称：对应参数文件每列的变量名，类似 Excel 文件的文件头，主要是作为后续引用的标识符，一般使用英文。通过“${变量名称}”就可以引用需要的文件数据
	- 忽略首行： 第一行不读取。比如图 2 的第一行我只是标示这一列是什么类型的数据，实际上并不是需要读取的业务数据，此时就可以采用忽略首行。
	- 分隔符：用来标示参数文件中的分隔符号，与参数文件中的分隔符保持一致即可。
	- 遇到文件结束符再次循环：是否循环读取参数文件内容。因为 CSV Data Set Config 一次读入一行，如果设置的循环次数超过文本的行数，标示为 True 就是继续再从头开始读入。
	- 遇到文件结束符停止线程：读取到参数文件末尾时，是否停止读取线程，默认为 False。如果“遇到文件结束符再次循环”已经设置为 True 了，这个选项就没有意义了。
	- 线程共享模式：这个适用范围是一个脚本里多线程组的情况。所有线程是默认选项，代表当前测试计划中的所有线程中的所有的线程都有效；当前线程组代表当前线程组中的线程有效；当前线程则表示当前线程有效。一般情况下，我们选择默认选项“所有线程”就好，“当前线程组”和“当前线程”很少会用到。
1. 特殊的参数化：关联
	关联是将上个请求的数据提取需要的部分放到下个请求中，通过关联我们可以获取到满足业务特性的不同数据，因此可以认为是一种特殊的参数化。
1. JMeter 如何实现关联
	- JMeter实现关联有 3 种方式：
		- 边界提取器，通过左右边界的方式关联需要的数据；
		- Json Extractor提取器，针对返回的 json 数据类型；
		- 正则表达式提取器，通过正则表达式去提取数据，实现关联。(最为常用)
	- 正则表达式提取器中每一项的含义。
		- 引用名称：自己定义的变量名称以及后续请求将要引用到的变量名。在图中我填写的是“token”，则引用方式是“${token}”。
		- 正则表达式：提取内容的正则表达式。“( )”括起来的部分就是需要提取的，“.”点号表示匹配任何字符串，“+”表示一次或多次，“？”表示找到第一个匹配项后停止。
		- 模板：用“$ $”引用，表示解析到的第几个值给 token，图 4 中的正则表达式如下：$1$ 表示匹配的第一个值.
		- 匹配数字：0 代表随机取值，1 代表第一个值。
		- 缺省值：正则匹配失败时的取值。比如这里我设置的是 null（token 值取不到时就会用 null 代替）。
## 构建并执行JMeter脚本的正确姿势
### 脚本构建
1. 常见的误区
	一个线程组、一条链路走到底。脚本中的设计思路实际上也是你对性能测试模型的理解，能够反馈出模型中的用户访问比例分布。
1. 未提取公共部分，增加脚本管理难度
	一般全链路级别的测试脚本里可能会包含上百个接口，对于一些 host 和端口号，并不需要每一个接口都去配置，我们可以使用一个 HTTP 请求默认值去做公共部分
1. 查看结果树使用频率高
	在脚本调试过程中，我们通常会添加结果树来实时查看返回数据的正确性。这个插件本身是比较消耗性能的，在正式压测中应当禁止使用。一般来说，在脚本调试中通过作用域的思想去配置一个查看结果树就可以了，不要过度使用，不然等到正式压测的时候，一个个地禁用结果树不仅会消耗时间，还容易遗漏。
1. 脚本逻辑复杂
	在编写脚本的过程中为了区分业务逻辑，会使用很多插件，比如 if 判断、循环， 这些插件虽然可以让你进入不同的业务场景，但会增加脚本的复杂度，影响发起压力的效率。
- 规范的脚本构建，要做到真实和精简。
	- 真实在于你的脚本可以体现出真实的用户访问场景；
	- 精简在于少使用周边的插件，比如通过 JMeter 去监控服务器资源，这样的监控不仅简单粗糙，而且较大地影响 JMeter 的压力发起的效率。
### 脚本执行
1. 界面化执行性能测试
	图形化模式只让你调试，不要进行压测。图形化的压测方式会消耗较多的客户端性能，在压测过程中容易因为客户端问题导致内存溢出。
1. 命令行执行方式
	```
	jmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder]
	```
	- n 表示在非 GUI 模式下运行 JMeter；
	- t 表示要运行的 JMeter 测试脚本文件，一般是 jmx 结尾的文件；
	- l 表示记录结果的文件，默认以 jtl 结尾；
	- e 表示测试完成后生成测试报表；
	- o 表示指定的生成结果文件夹位置。
1. 命令行方式存在2个问题
	- 看不到实时的接口返回报错的具体信息；
	- 看不到混合场景下的每个接口的实时处理能力。
	- 问题解决：
		- jmeter.log看到只能显示报错率，但看不到具体的报错内容，那如何去解决呢？一般会使用 beanshell，把判定为报错的内容增加到log里。
			```javascript
			String response = prev.getResponseDataAsString();
			//获取接口响应信息
			String code = prev.getResponseCode();
			//获取接口响应状态码
			if (code.equals("200")){//根据返回状态码判断
				log.info("Respnse is " + response);
				//打印正确的返回信息，建议调试使用避免无谓的性能消耗
			}else {
				log.error("Error Response is"+response);
				//打印错误的返回信息
				}
			```
			- 客户端的日志只是我们需要关注的点之一，排查错误的根因还需要结合服务端的报错日志，一般来说服务端的报错日志都有相关的平台记录和查询，比较原始的方式也可以根据服务器的路径找相关日志。
		- 如果想实时且直观地看到每个接口的处理能力，我比较推荐 JMeter+InfluxDB+Grafana 的方式。
			- jmeter集群--》influxdb存储--》grafana实时数据展示
			- **InfluxDB**
			- InfluxDB 是 Go 语言编写的时间序列数据库，用于处理海量写入与负载查询。涉及大量时间戳数据的任何用例（包括 DevOps 监控、应用程序指标等）。我认为 InfluxDB 最大的特点在于可以按照时间序列面对海量数据时候的高性能读写能力，非常适合在性能测试场景下用作数据存储。
			- 安装
				```
				#wgethttps://dl.influxdata.com/influxdb/releases/influxdb-1.1.0.x86_64.rpm
				#rpm -ivh Influxdb-1.1.0.x86_64.rpm
				#systemctl enable Influxdb
				#systemctl start Influxdb
				#systemctl status Influxdb  （查看 Influxdb 状态）
				```
			- 基本操作
				```
				#influx 
				linux 命令行模式下进入数据库
				#show databases
				查看库
				create database jmeter；
				建库
				use jmeter
				使用该库
				show measurements;
				查看库下面的表
				```
			- InfluxDB 成功安装并且建库之后，我们就可以来配置 JMeter 脚本了。配置过程可以分为以下 3 步
				- 添加核心插件，在 listener 组件中选择 Backend Listener
				- Backend Listener implementation 中选择第二项
				- 配置 InfluxDB URL，示例“http://127.0.0.1:8086/write?db=jmeter”；IP 为实际 InfluxDB 地址的 IP，DB 的值是 InfluxDB 中创建的库名字
			- **Grafana**
			- Grafana 是一个跨平台的开源的度量分析和可视化工具，纯 JavaScript 开发的前端工具，通过访问库（如 InfluxDB），展示自定义报表、显示图表等。大多时候用在时序数据的监控上。Grafana 功能强大、UI 灵活，并且提供了丰富的插件。
			- 安装
				```
				#wget https://dl.grafana.com/oss/release/grafana-6.4.4-1.x86_64.rpm
				#下载 granafa
				#yum install  Grafana-6.4.4-1.x86_64.rpm
				#安装，遇到需要输入的直接 y 就 ok；
				#systemctl start Grafana-server
				#systemctl enable Grafana-server
				#启动 Grafana
				#/etc/Grafana/Grafana.ini
				配置文件路径，一般保持默认配置即可。
				#systemctl status  firewalld.service
				查看防火墙状态，防止出现其他干扰问题，最好关闭
				登录访问 Grafana 访问：http://127.0.1.1:3000（ip 自行替换，3000 为默认端口）
				默认账号/密码：admin/admin
				```
			- 数据源配置
				- 配置安装的 InfluxDB 地址和端口号	
			- 导入 JMeter 模板
				- 为了达到更好的展示效果，Grafana 官网提供了针对性的展示模版。先下载[JMeter模板](https://grafana.com/Grafana/dashboards?search=InfluxDB)，然后再导入 Grafana。
				- 可以以此为基础，进行多接口的数据采集，相应增加脚本里的 Backend Listener 插件，区分不同的 application name 名称，你会看到不同的接口数据都进入 influxdb 数据库中。并且 Grafana 从 Edit 中进入， 你可以根据不同的 application name 修改 SQL 来区分展示。
## JMeter二次开发（backlog）
## 基于JMeter API开发性能测试平台（backlog）
## Nginx在系统架构中的作用
### Nginx重要的两个概念
1. 代理
	- 正向代理
		- 正向代理的特点是你非常清楚地知道你要去哪儿，访问什么服务器，但服务器并不关心你的出发地是哪里，它只知道你从哪个代理服务器过来。
	- 反向代理
		- 先来说一下应用场景，比如我们的内部服务器集群，是不可能直接暴露出来让外网访问的，这样安全风险就非常大；再比如现在很多网站为了提高性能都采用了分布式部署，通过多台服务器来缓减服务端的压力，这些都可以通过 Nginx 来完成。
		- 那我们的外网用户如何能够访问到内部的应用呢，Nginx 可以暴露端口给外网用户访问，当接收到请求之后分发给内部的服务器，此时的 Nginx 扮演的是反向代理的角色。这样一个过程，客户端是明确的，但对于访问到哪台具体的应用服务器是不明确的。
1. 负载均衡
	负载均衡是 Nginx 最重要也是最常见的功能
	- **轮询**
	- 也就是使用平均分配的方式，将每个请求依次分配到配置的后端服务器上。除非有服务宕机，才会停止分发。
	```shell script
	upstream localhost {
	//分发到各应用服务
		  server  127.0.0.1:7070;
		  server  127.0.0.1:7071;
		}
		server{
	//Nginx核心监听端口
			listen 8012;
			server_name localhost;
			location / {
					proxy_pass         http://localhost;
					proxy_set_header   Host             $host;
					proxy_set_header   X-Real-IP        $remote_addr;
					proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
			}
	}
	```
	- **权重**
	- 权重即配置轮询的比重，为什么需要这么配置呢？在真实的互联网场景下，很多服务器上都会配置多个应用，这样会导致每台服务器的资源占用不一致，所以在分布式部署配置下也需要注意这一点。相对空闲的机器可以多配置访问比例；比较繁忙的机器可以少配置一些。
	```shell script
    upstream test {
    server ip1:8080 weight=9;
    server ip2:8081 weight=1;
    }
	```
	- **ip_hash**
	- 但上面两种配置方式在电商场景下有个很常见的问题，比如你登录了一个网站，登录信息已经保存到 a 机器，但当你做后续操作时的请求会到 b 机器，那么就获取不到你原来登录的信息，此时你就需要重新登录了。这样的情况是用户肯定不能接受的，ip_hash 模式就可以很好地解决这个问题，让每次访问能基于同一用户访问固定的服务器。
	```shell script
	upstream test {
		ip_hash;
		server localhost:8080;
		server localhost:8081;
	}
	```
### Nginx日志分析
1. awk
	- awk 可以将文本中的内容按行去读取，然后将读取出来的行按照规定的分隔符去提取你所需要的内容。
	- awk 常用参数是 -F 指定分隔符。
	```shell script
	比如以下代码就是以 : 为分隔符，寻找以 root 开头的行数据，打印第 7 列
	awk -F : '/^root/{print $7}' /etc/passwd
	/bin/bash
	```
	```shell script
	以下代码表示以 begin 开头、end 结尾，打印第 1 列数据。
	awk -F : 'BEGIN{print "begin"}{print $1} END{print "end"}' /etc/passwd
	begin
	root
	..
	end
	```
1. Sed
	- Sed 是一个流编辑器，一次只能处理一行内容，需要注意的是 sed 并不改变文本本身的内容，它只是把结果存放在临时缓冲区中。
	- sed 常用的参数有：
		- a 表示新增；
		- i 表示插入；
		- c 表示取代；
		- d 表示删除。
	```shell script
	设置一个文本文件，每行只有一个数字
	[root@JD data]# cat sed.txt
	1
	2
	3
	```
	```shell script
	在第一行下新增 4
	[root@JD data]# sed '1a 4' sed.txt
	1
	4
	2
	3
	```
	看下原来的文本，你会发现没有任何改动
1. Sort
	- Sort 的默认方式就是把第一列根据 ASCII 值排序输出。常用参数有：
		- n，依照数值的大小排序；
		- r，以相反的顺序来排序；
		- k，选择以某个区间进行排序。
	```shell script
	[root@JD data]# sort -r sed.txt
	3
	2
	1
	```
1. uniq
	- uniq 用于检查或者统计文本出现的重复行，常用参数是 -c，它用于连续重复行次数的统计。
	```shell script
	构造一个 uniq.txt
	[root@JD data]# cat uniq.txt
	hello
	hello
	quanquan
	quanquan
	quanquan
	nihao
	```
	```
	然后对 uniq.txt 进行重复数据统计，并根据重复次数由大到小排序
	[root@JD data]# uniq -c uniq.txt |sort -r
	 3 quanquan
	 2 hello
	 1 nihao
	```
学完了这些基础命令，我带你来看 Nginx 日志分析，如果你不清楚你的 Nginx 日志地址，查看nginx.conf 文件的配置即可
```ini
120.204.101.238 - - [29/Nov/2020:14:19:39 +0800] "GET /hello/map HTTP/1.1" 200 202 
47.92.11.105 - - [29/Nov/2020:14:19:39 +0800] "GET /hello/map HTTP/1.1" 200 202 
185.39.101.238 - - [29/Nov/2020:14:19:39 +0800] "GET /hello/list HTTP/1.1" 200 150 "-
101.132.114.23 - - [29/Nov/2020:14:19:39 +0800] "GET /hello/list HTTP/1.1" 200 150 "-
120.204.101.238 - - [29/Nov/2020:14:19:39 +0800] "POST /v1/login HTTP/1.1" 200 36 "-
...
```
```shell script
打印第 7 列
awk '{print $7}'  access.log
/hello/list
/v1/login
/hello/list
/hello/map
```
```shell script
统计访问接口的比例分布
cat access.log |awk '{print $7}'|sort|uniq -c|sort -n -k -r
先 sort 排序，这样可以将相同的接口访问路径合并一起；
再使用 uniq -c 统计连续访问的次数；
最后根据访问次数排序，便可以得到结果。
  87280 /hello/list
  18892 /hello/map
  12846 /v1/login
```
## 如何制定性能测试目标
制定目标可以确定既定的测试范围内需要达到的性能预期结果。制定目标后，你才会对本次性能测试的核心目标有清晰的认知，并指导你进行后续的测试活动，包括测试所需要的资源以及测试的停止条件等。
1. TPS
	- 在实际生产中，无论是网关还是服务通常都是记录一定时间内的访问请求次数，所以在业内，性能测试往往以 TPS（Transactions Per Second）作为最重要的度量指标，因为它具备可度量和通用性的特质。
		- 可度量指TPS是真实客观且明确的衡量指标；
		- 通用性指无论在运维角度还是测试角度，TPS 都可以达成一致的定义。
1. 响应时间
	- 响应时间和用户体验密切相关，我们往往把一次请求从客户端发出到返回客户端的时间作为响应时间。在实际工作中，我们会以 TPS 的量级来限制响应时间必须在多久之内。以下图，从最左侧的客户端到最右侧的数据持久化再返回到客户端，这样一个来回的过程就是一次完整的请求响应时间。
	![](~@img/uTools_1656212778361.png)
	上图描述的是在正常情况下的响应流程，但当你有了一定的性能测试实践之后，你会发现这样的过程并不是绝对的。比如有的业务第一次在数据库请求到数据后，应用层本地缓存会将数据存储在应用服务器上，也就是接下来在缓存有效时间内不会再去数据库取数据，而是在应用层得到数据后就会直接返回，所以响应时间会比第一次低不少，这也是随着性能测试的进行响应时间变低的原因之一
1. 报错率
	- 报错率的计算方式是在统计时间范围内不符合返回期望的请求数除以总共的请求数。在测试中，这一指标不符合期望的话一般体现在对结果的校验上，一般会分为三个层面进行校验：
		- 状态码的校验，这在性能工具中不需要特别设置，如 4XX、5XX 这样的状态码会直接报错；
		- 业务层面的校验，为了保证业务的基本准确性，会通过返回的数据包进行校验；
		- 数据库校验， 相对于业务测试，性能测试的每一次请求不会都做数据库校验，这样会影响性能测试结果，我一般会在一轮性能测试之后去统计落库数据的数量和状态是否正常。
### 制定性能测试指标
1. 以衡量系统的处理能力为核心目标
	- 这一般是性能测试的主要目标，用来评估当前系统的处理能力和容量方面的规划，评估这个目标最重要的是对数据的客观分析。
	- 对于每一个接口都会有访问计数，这是目前业内比较常见的，也是衡量接口访问能力最准确的指标之一。一般大公司会自己开发相应的监控工具，发展中的公司也会使用一些开源或者商业工具进行监控。通过时间维度和服务维度来统计。
	- **时间维度**
		- 首先确定哪些天数的访问量是比较高的，先以天作为维度统计
		- 选取了天数之后，再以小时为维度，确定哪些时间节点的访问量是比较高的。
	- **服务维度**
		网关一般是请求进入应用层的第一个入口，也是统计网站入口访问量的方式之一。当我们的请求通过网关之后会下发到各个业务应用服务，按照确定的时间节点去统计各个服务的访问量数据。完成服务级的访问数据统计之后，继续按照时间维度统计服务下的接口访问数据。
1. 系统的健壮性
	如内存泄漏、并发死锁、超卖问题，这些也需要在性能测试方向上进行。
1. 系统的稳定性
	- 一个是正确率，这不一定要在高并发下完成，但我们要保证业务长时间运行的正确率能够达到 99.9999% 以上；
	- 另一个是处理能力，可以选取性能测试场景中的混合场景来执行，这里我们需要观察两点：
		- 整体处理能力是否稳定，会不会存在处理能力的下滑；
		- 接口之间的比例是否稳定，随着时间的进行接口之间的访问比例会不会偏离。
1. 专项能力是否达标
	以上列举的几乎都是以业务接口为测试目标，其实在实际的压测活动中，也存在中间件甚至硬件的性能测试，比如 Nginx、Kafka、防火墙等。这些往往不会作为最终的性能测试目标，但会在全链路排障和专项测试中有所涉及。这部分的性能测试基本上是用来判断当前的环境配置的节点数，以及配置所能达到的最大处理能力，为全链路性能测试提供数据支撑。 
## 性能测试场景的分类和意义
### 基准场景
基准场景是指单线程或者少量线程（一般在 5 个线程以下）对单接口进行测试，然后将测试结果作为基准数据，在系统调优或者评估的过程中，通过运行相同的业务接口比较测试结果，为系统的优化以及后续测试流程提供决策数据。
- 作用
	- 验证测试脚本及测试参数的正确性，同时也可以验证脚本数据是否能够支持重复性测试等；
	- 通过少量线程访问系统获取结果数据，作为对比参考基准；
	- 根据测试结果，初步判断可能成为系统瓶颈的场景，并决定是否进行后续的测试；
	- 基准场景的结果被一部分公司作为上线的基线指标，不达到要求是不允许上线的，这样的场景也经常被固化成自动化的脚本定时触发和巡检。
### 单接口负载场景
单接口负载场景就是通过模拟多线程对单接口进行负载测试。具体做法是选定线程数后持续循环运行一定时间，比如分别运行 100 线程、200 线程、300线程等，一般相同线程数运行 10～15 min，然后获取事务响应时间、TPS、报错率，监测测试系统的各服务器资源使用情况（CPU、内存、磁盘、网络等），把具体数据记录之后再开始跑下一个线程数。每一组线程数级别会有对应的 TPS，直到你找到 TPS 的拐点。如下图所示，横坐标是线程数，纵坐标是 TPS，线程数增加到 400 时出现了拐点。
![](~@img/uTools_1656217644330.png)
- 注意的点有两个
	- 使用工具做性能测试时，动辄就是上千的线程数，更加倾向于从一个相对比较低的线程数梯度增加，这样才能够比较清晰地找到 TPS 的拐点。
	- 建议为每个虚拟用户级别做单独的场景，网上绝大部分的教程，在一个场景中做了很多梯度，其实很不利于分析和诊断。因为并不是每一个量级的性能表现都是类似的，而且一个场景多梯度出来的报表也可能没你想象中的清晰明了。在 JMeter 的聚合报告中还会将结果数据平均化，这样的方式并不能准确地记录每个线程梯度对应的 TPS。而在一个场景里先固定虚拟用户可以将自己的精力聚焦在诊断上。
### 混合场景负载测试
- 混合场景是性能测试中最重要的场景之一，这个场景是为了最大程度模拟用户真实的操作。
- 使用JMeter去控制场景比例
	- JMeter 提供了一个能较好地解决这个问题的插件，叫作吞吐量控制器，它在逻辑控制器组件中
	- 默认的情况下使用的是百分比模式，也就是 Percent Excutions。吞吐量一栏对应的是 TPS 占比
以上是所说的基石场景，包括基准测试、负载测试、混合场景测试等，这三个场景是有依次执行的顺序关系的，按照顺序执行更容易发现问题且减少不必要的工作，比如你连基准测试都不通过，就没有必要进行负载测试了。

### 异常性能测试
- 性能测试也是存在异常测试的，顾名思义就是在系统异常的情况下看系统的处理能力或者是通过处理后的恢复能力是如何的。
- 比如在架构的高可用方面，遇到服务的上下线、数据库的主从切换等这些情况的时延是多少、处理能力能不能达到预期标准。另外在目前的电商应用架构中，大促遇到紧急情况经常需要限流和熔断，可能你经常听到这两个词，但不是特别清楚两者的区别。
- 限流就是控制单位时间内的请求量，比如说早晚高峰坐地铁，很多入口都会放隔离带，降低乘客流动速度，这就是一种限流方式。
- 熔断就比较直接了，当判断到调用的依赖服务报错到达一定数量后，直接返回一个既定的数据，将不再访问该服务。就像家中的保险丝一样，到达一定条件后，会自行断电，以保障电路安全。所以我们也会测试触发限流和熔断所设置的阈值，并观察在触发后的系统表现是如何的。
### 稳定性性能测试
- 性能测试中的稳定性测试是通过给系统加载一定压力的情况下，运行较长一段时间，验证系统是否稳定。通常是采用典型混合场景，应用系统运行 72 小时，查看系统运行指数是否平稳。
- 稳定性测试的注意点
- 稳定性测试在性能测试中是一个相对严苛的场景，因为在 72 小时中可能发生的事情太多了，不仅仅是业务承载的问题，还包括你准备的数据、客户端稳定性，甚至硬件设备断网断电等。任何一项意外的发生，都会造成场景的失败。稳定性测试的监控级别也应当更高，一旦有问题，立即钉钉或者电话通知，所以稳定性测试之前需要有充足的预案和监控报警。
### 什么情况下可以停止负载测试
- 在梯度增加线程数时，TPS 一般会随之发生变化，当你能够根据 TPS 的变化找到相应的峰值且这个值也是符合预期时，便可以停止负载测试了。
- 很多时候当你还没有到拐点时，接口就可能在报错了，那遇到这样的情况是继续测试还是停止测试呢？这其实是一个约定的问题，即测试的结束条件是什么？
	- 理想的情况下自然是达到目标就停止了。
	- 那不理想呢？根据经验，会在测试之前组内协商出场景异常情况下的停止条件，比如 CPU 达到 70%，响应时间超过 500 ms，接口正确率低于 99% 等，当触发这些条件时，我将不会继续加线程进行测试了。

## 制定一份有效的性能测试方案（backlog）
## 命令行监控Linux服务器
### 层次清晰
1. 硬件层
	一般包含了 CPU 的使用率、内存使用率、磁盘和网络读写速度等，通过这些指标能够反馈出系统运行的基本情况，以及不同的 TPS 量级会消耗多少硬件资源。
1. 系统层
	系统层监控包括连接请求数、拒绝数、丢包率、请求超时等，相对于基础的硬件监控而言，这些指标更能够反映出目前系统存在的瓶颈，从而为根因问题的定位提供有力的线索。
1. 链路层
	链路层是直接面向架构和代码的，它的监控能够帮助你更加准确地看到代码执行了哪些函数，涉及哪些服务，并且能够较为清晰地看到函数之间的调用耗时，还可以帮助你定位代码存在的问题。
1. 业务层
	业务层监控本意是帮助你判断用户输入是否合规，代码逻辑是否健壮。对于性能测试而言，业务层的监控可以帮助你发现脚本参数问题以及高并发下业务逻辑运行是否正常等，比如随着测试的进行，可能会存在商品库存不足的情况。如果有业务层面的监控，当库存低于某阈值时，可以进行一定的提示以规避此类问题。
### 全面覆盖
除了应用层的监控，你还需要考虑底层链路的监控，比如防火墙、F5 负载均衡等
### 定向深入
首先通过基本的监控可以获得一些异常点，比如 CPU 高了、磁盘在等待，这些说白了是表象问题。对于监控，是否有定位根因问题的手段，CPU 高了，需不需要进行线程分析，需要哪些权限和定位工具，这些在监控部署时都需要考虑到。
1. CPU
	- top 是我们查看各个进程的资源占用状况最常用的命令。
	```shell script
	top - 18:17:47 up 158 days,  9:32,  2 users,
	load average: 0.07, 0.15, 0.21
	Tasks: 154 total,   1 running, 152 sleeping,   0 stopped,   1 zombie
	%Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 id,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st
	KiB Mem :  8010676 total,   337308 free,  6036100 used,  1637268 buff/cache
	KiB Swap:        0 total,        0 free,        0 used.  1223072 avail Mem
	以下省略
	```
	- **load average**
	```shell script
    load average: 0.07, 0.15, 0.21
    ```
	- 三个数字都是代表进程队列的长度，从左到右分别表示一分钟、 五分钟和十五分钟的数据，数字越小压力值就越低，数字越大则压力越高
	- 以单核处理器为例
		- 0 表示没有任何车辆需要通过；
		- 从 0 到 1 可以认为很流畅，车辆不需要任何等待就可以通过；
		- 1 表示正好在这个通道可接受范围之内；
		- 超过 1 就已经有车辆在后面排队了。
	- 所以理想情况下，希望平均负载值在 1 以下。如果是 1 就代表目前没有可用资源了。在实际情况中，很多运维同学会把理想负载设置在 0.7 以下，这也是业内的一个“经验值”。
	- 多核 CPU 的话，负载数值 / CPU 核数在 0.00~1.00 之间表示正常，理想值也是在 0.7 以内。
	-  **CPU 状态**
	```shell script
     %Cpu(s):  3.9 us,  1.3 sy,  0.0 ni, 94.6 id,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st
    ```
	- us(user) 列显示了用户进程所花费 CPU 时间的百分比。这个数值越高，说明用户进程消耗的 CPU 时间越多，可以用来分析代码中的 CPU 消耗热点。
	- sy(system) 列表示系统进程消耗的 CPU 时间百分比。
	- ni(?) 列表示改变优先级的进程占用 CPU 的百分比。
	- id(idle) 列表示 CPU 处于空闲状态的时间百分比。
	- wa(?) 列显示了 I/O 等待所占用的 CPU 时间的百分比，这里 wa 的参考值为 0.5，如果长期高于这个参考值，需要注意是否存在磁盘瓶颈。
	- hi(hardware interrupt) 列表示硬件中断占用 CPU 时间百分比。
	- si(software interrupt) 列表示软件中断占用 CPU 时间百分比。
	- st(?) 列表示当系统运行在虚拟机中时，当前虚拟机在等待 CPU 为它服务的时间。
	- 在已经输入 top 的情况下再输入数字 1，可以查看 CPU 的核数和每个核的运行状态
	```shell script
    %Cpu0 : 3.0 us, 1.7 sy, 0.0 ni, 95.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
    %Cpu1 : 2.4 us, 1.0 sy, 0.0 ni, 96.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
    ```
	- 看 CPU 的使用率时，只看 us 这个数值，是不准确的。除了用户进程，还有其他系统进程会占用 CPU，所以实际 CPU 的使用率可以用 100 减去空闲值（id）去计算。
1. 内存
    通过 free 来查看 Linux 内存使用情况
    ```shell script
    [root@JD ~]# free -m
             total    used    free   shared  buff/cache  available
    Mem:      7822    5917     302     373     1602        1195
    Swap:       0       0       0
    ```
	- total、used、free 它们分别是总的物理内存大小、已经被使用的物理内存和空闲的物理内存值是多少。
	- 为什么 free 值很低却未必代表内存达到瓶颈呢？
	- 这和 Linux 内核机制有关系，简单来说，内存空间会开辟 buffer 和 cache 缓冲区，对于物理内存来说，这都属于被使用过的内存。而应用需要内存时，如果没有可用的 free 内存，内核就会从缓冲区回收内存以满足要求，当 free 值很低的时候，如上代码中的 available 就能体现出缓冲区可用内存的大小，这个指标可以比较真实地反映出内存是否达到使用上限。
1. 磁盘
	- **iostat**
	```shell script
    [root@JD ~]# iostat -x
    Linux 3.10.0-514.el7.x86_64 (JD)    01/18/2021   _x86_64_    (2 CPU)
    avg-cpu: %user %nice %system %iowait %steal %idle
			 5.24  0.00  1.57    0.07    0.00   93.12
    Device:   rrqm/s wrqm/s  r/s   w/s   rkB/s  wkB/s  avgrq-sz avgqu-sz await  r_await w_await svctm %util
    vda       0.00   0.29    0.57  5.30  20.50  630.14 221.82   0.07     11.53  59.83   6.36    1.18  0.69
    ```
	- idle 代表磁盘空闲百分比；
	- util 接近 100%，表示磁盘产生的 I/O 请求太多，I/O 系统已经满负荷在工作，该磁盘可能存在瓶颈；
	- svctm 代表平均每次设备 I/O 操作的服务时间 (毫秒)。
	- 组合看这些指标，如果 idle 长期在 50% 以下，util 值在 50% 以上以及 svctm 高于 10ms，说明磁盘可能存在一定的问题。接着我会定位到具体是哪个进程造成的磁盘瓶颈
	- **iotop**
	- iotop 这个命令并不是 linux 原生，需安装。
	- 输入iotop，就能清楚地看到哪些进程在消耗磁盘资源。
	```shell script
    6448  be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % ifrit-agent
    14647 be/4 root        0.00 B/s    7.70 K/s  0.00 %  0.00 % java -Dserver.port=9080
    ```
1. 网络
	- **netstat**
	- netstat 能提供 TCP 和 UDP 的连接状态等统计信息，可以简单判断网络是否存在堵塞。
	```shell script
    [root@JD ~]# netstat
    Active Internet connections (w/o servers)
    Proto Recv-Q Send-Q Local Address           Foreign Address         State
    tcp        0      1 JD:49190                169.254.169.250:http    FIN_WAIT1
    tcp        0      0 JD:39444                169.254.169.254:http    TIME_WAIT
    tcp        0      0 JD:us-srv               worker-18.:sentinel-ent ESTABLISHED
    ```
	- Proto：协议名（可以 TCP 协议或者 UDP 协议）。
	- recv-Q：网络接收队列还有多少请求在排队。
	- send-Q：网络发送队列有多少请求在排队。
	- recv-Q 和 send-Q 如果长期不为 0，很可能存在网络拥堵，这个是判断网络瓶颈的重要依据。
	- Foreign Address：与本机端口通信的外部 socket。
	- State：TCP 的连接状态。
## 分布式服务链路监控以及报警方案（backlog）
## 把可视化监控也做得酷炫（backlog）
## Docker制作、运行以及监控（backlog）
## 从CPU飙升定位到热点方法（backlog）
## 基于JVM分析内存使用对象（backlog）
## 通过Arthas定位代码链路问题（backlog）
## 应对Redis缓存穿透、击穿和雪崩
由于数据库的数据是存在硬盘上，硬盘的 I/O 读写瓶颈会直接影响并发量。磁盘 I/O 读写时瓶颈，采用速度更快的内存来存储常用但数据量不算大的数据。
![](~@img/uTools_1656245657230.png)
- 最常使用的基于内存的数据库就是 Redis 和 MemCached
- Redis 和 Memcached 对比
	1. 存储方式
		- MemCached 目前只支持单一的数据结构 Key-Value 形式；
		- Redis 支持多种数据结构，有字符串、列表、集合、散列表、有序集合等。
	1. 持久化
		- 持久化就是把数据从内存永久存储到磁盘里，可以防止断电等异常情况下数据丢失等问题。目前 Redis 支持持久化，而 MemCached 不支持。遇到灾难，MemCached 无法恢复数据，Redis 可以恢复数据，保证了数据的安全性。
		- 从以上特点可以看出 Redis 在数据多样性和安全性上远高于 MemCached。MemCachded 使用频率越来越低，绝大多数的业务场景使用 Redis 居多。
- Redis特性
	- 主从复制功能
		- 虽然数据在内存中读写速度比较快，但是在高并发情况下也会产生读写压力特别大的情况，Redis 针对这一情况提供了主从复制功能。
		- 主从复制的好处有如下两点：
		- 提供了 Redis 扩展性，当一台 Redis 不够用时，可以增加多台 Redis 作为从服务器向外提供服务；
		- 提供了数据备份和冗余服务器，当 Redis 主服务器意外宕机，从服务器可以顶替主服务器向外提供服务，增加了系统的高可用性。
	- 脚本操作
		- Redis 提供了 lua 脚本操作，你可以将 Redis 存取操作写到 lua 脚本里，然后通过 Redis 提供的 API 来执行 lua 脚本，这样就可以实现 Redis 相关操作。
		- 我们同样可以用 Redis 提供的 API 直接实现 Redis 相关操作，那么为什么有时候又要绕一圈去操作 lua 脚本呢？因为 lua 脚本能够保证操作的原子性，即所有的操作当作一个操作，要么全部失败要么全部成功。而直接使用 API 不一定能保证一连串操作的原子性，所以当需要保证原子性的时候需要使用 lua 脚本。
	- 发布与订阅
		- 该特性可以将 Redis 作为消息中间件，在服务端产生消息，然后在客户端消费消息队列里的消息，但是作为消息队列不是 Redis 的强项，所以不推荐使用。比如 Redis 作为消息队列消息并非完全可靠，会产生消息丢失的问题，并且也不支持消息分组。在性能上，如果入队和出队操作频繁，那 Redis 性能比起 RabbitMq 等常用消息队列来说还是有差距的。
- Redis缺点
	- 缓存穿透
		- 缓存穿透的情况是 Redis 和 MySQL 数据库都没有这条数据，但是用户不断并发发起请求，请求压力会同时落到数据库和缓存上，这样的情况相对于设计初衷来说，对系统的压力就会大很多了，而且这也是黑客发起攻击的手段之一，找寻你的系统是否存在漏洞。
		- 那在项目中如果遇到缓存穿透我们该如何解决呢？
		- 遇到缓存穿透，我们可以在请求访问缓存和数据库都没查到数据时，给一个默认值或者 Null 值，即 Key-Null。然后该缓存值的有效时间可以设置得短点，比如 30s。在业务代码中判断如果是 Null 值就取消查询数据库，或者间隔 30s 之后重试，这样的方式可以大幅度减轻数据库的查询压力。
	- 缓存击穿
		- 单个数据在缓存中不存在，而在数据库中存在。一般这种情况都是缓存失效导致的，在缓存失效的时间段有大量并发用户访问，首先访问缓存，因为 Key 已经过期了，所以查不到数据，然后所有查询压力都会落到数据库上，造成数据库的压力过大。并且还有可能因为并发问题导致重复更新缓存而过多占用缓存资源。
		- 在项目中如果遇到缓存击穿问题，该如何解决呢？
			- 对于一些经常被访问的热点数据，可以根据业务特性主动检查使其 Redis 数据永不过期，当然这样的设置并不代表说这条数据一直不更新而处在 Redis 中，而是根据数据字段中的失效时间和系统时间的对比主动检查更新数据，使 Redis 数据不会过期；
			- 通过后台定时刷新，根据缓存失效时间节点去批量刷新缓存数据，这个适合 Key 失效时间相对固定的场景。
	- 缓存雪崩
		- 大量数据在同一时间失效，会造成数据库查询压力过大导致宕机。缓存雪崩与缓存击穿的区别在于缓存击穿是单个数据失效，缓存雪崩是多个数据同一时间失效。
		- 在项目中如果遇到缓存雪崩的问题，我们该如何解决呢？以下 3 种方法可以帮我们解决。
			- 如果程序设置的缓存过期时间统一为一个固定的值，比如 5s、10s、15s 等等，那么很有可能出现大量数据在同一时间失效。这个时候我们可以设置不同的过期时间，比如统一时间加上一个随机时间，这样可以让缓存的时间尽量均匀分布一点。
			- 不设置过期时间，让程序的定时任务自动定时更新或者清除缓存
			- 使用集群化的方式，保证高可用。
## 优化MySQL性能
### 一次SQL的查询过程是怎样的
1. 客户端发送一个查询 SQL 给数据库服务器。
2. 服务器先检查查询**缓存**，如果命中，也就是查询缓存中有这条记录，那么便直接返回缓存中的结果。如果没有命中，则进入下一阶段（解析器）。
3. 服务器由**解析器**检查 SQL 语法是否正确，然后由**预处理器**检查 SQL 中的表和字段是否存在，最后由**查询器**生成执行计划，也就是 SQL 的执行方式或者步骤。
4. MySQL 根据**优化器**生成的执行计划，调用存储引擎的 API 来执行查询。
5. 将结果返回给客户端。
![](~@img/uTools_1656248060315.png)
### 影响性能的关键点有哪些
比如硬件层面、系统层面等等。但在性能领域中，一个不能忽略的问题是你需要考虑影响的面有多少，以及如何优化才是最具有性价比的，如图：
![](~@img/uTools_1656248218789.png)
- 从上往下看：
	- SQL 语句和索引相关问题是最常见的，带来的价值也是最明显的；
	- 系统配置库表结构带来的价值次之；
	- 而硬件层次的优化优先级是不高的。
1. 硬件配置
	对于数据库处理复杂 SQL 而言，尽量选择高频 CPU，而且数据库一般都会开辟缓存池来存放数据，所以在服务器选型的时候内存大小也需要考虑。一般来说数据库服务器的硬件配置的重要性高于应用服务器配置
1. 系统配置选项
	- **max_connections**，MySQL 可以接收到的最大连接数
	```sql
	 mysql> show variables like '%max_connections%';
	+-----------------+-------+
	| Variable_name   | Value |
	+-----------------+-------+
	| max_connections | 151   |
	+-----------------+-------+
	```
	MySQL 的实际连接数
	```sql
	 mysql> show status like 'Threads%';
	+-------------------+-------+
	| Variable_name     | Value |
	+-------------------+-------+
	| Threads_cached    | 7     |
	| Threads_connected | 64    |
	| Threads_created   | 1705  |
	| Threads_running   | 1     |
	+-------------------+-------+
	```
	其中 Threads_connected 是你实际的连接数。如果 max_connections 的值设置较小，在高并发的情况下易出现 “too many connections” 这样的报错，我们可以通过如下命令调节配置从而减少此问题的发生，你可以根据所在公司的实际情况进行配置。
	```sql
     mysql> set global max_connections=500;
    ```
	- **innodb_buffer_pool_size**，InnoDB 存储引擎下 MySQL 的内存缓冲区大小
	- 首先 InnoDB 存储引擎是 MySQL 的默认存储引擎，使用也很广泛。缓冲池是什么呢？其实就和缓存类似，通过上一讲学习你可以知道，从磁盘读取数据效率是很低的，为了避免这个问题，MySQL 开辟了基于内存的缓冲池，核心做法就是把经常请求的热数据放入池中，如果请求交互的数据都在缓冲池中则会很高效，所以一般数据库缓冲池设置得会比较大，占到操作系统内存值的 70%～80%。
	- 如何评估缓冲池大小是否合理？
	- 我们可以通过计算缓存命中率来判断，公式为：(1-innodb_buffer_pool_reads/innodb_buffer_pool_read_request) * 100
	- 一般来说，当缓存命中率低于 90% 就说明需要加大缓冲池了
	```sql
	  show status like  'Innodb_buffer_pool_read_%';
	+---------------------------------------+----------+
	| Variable_name                         | Value    |
	+---------------------------------------+----------+
	| Innodb_buffer_pool_read_ahead_rnd     | 0        |
	| Innodb_buffer_pool_read_ahead         | 51       |
	| Innodb_buffer_pool_read_ahead_evicted | 0        |
	| Innodb_buffer_pool_read_requests      | 25688179 |
	| Innodb_buffer_pool_reads              | 2171     |
	+---------------------------------------+----------+
	```
	- **SQL优化**
	- **1>什么是慢SQL**
	- 从默认定义上来讲，执行超过 10s 的 SQL 都被定义为慢 SQL
	- 查看慢查询配置的时间：
	```sql
	mysql> show variables like 'long_query_time';
	+-----------------+-----------+
	| Variable_name   | Value     |
	+-----------------+-----------+
	| long_query_time | 10.000000 |
	```
	- 如果需要修改该配置为 1s，可以在 my.cnf 中添加，这样的方式需要重启 MySQL 服务
	```ini
	long_query_time=1
	```
	- **2>获取慢SQL**
	- 方式一：在my.cnf中配置
	```ini
	slow_query_log=1
	slow_query_log_file=/data/mysql-slow.log
	```
	- 方式二：使用show full processlist这个命令实时获取交互的SQL，通过观察state状态以及SQL出现的频率也能判断出来是不是慢SQL。
	- **3>分析慢SQL**
	- 关于慢 SQL，绝大多数原因都是 SQL 本身的问题，比如写的业务 SQL 不合理，返回了大量数据；表设计不合理需要多表的连接查询；索引的问题等。
	- 众多SQL问题中索引相关的问题也是最突出：
	- **索引缺失**
	- 索引是一种单独地、物理地对数据库表中一列或者多列进行排序的数据库结构。索引的作用相当于图书的目录，可以根据目录的页码快速找到所需要的内容。当数据库存在大量数据做查询操作，你就需要 check 是否存在索引，如果没有索引，会非常影响查询速度。
	- 在 InnoDB 中，我们可以简单地把索引分成两种：聚簇索引（主键）和普通索引。按照我的理解来看，聚簇索引是叶子节点保存了数据，而普通索引的叶子节点保存的是数据地址。
	- 通常推荐在区分度较高的字段上创建索引，这样效果比较好，比如，一个会员系统中，给用户名建索引，查询时候可以快速定位到要找的数据，而给性别字段建索引则没有意义。
	- **索引失效**
	- 添加索引只是其中的一个必要步骤，并不是添加完成后就万事大吉了。在一些情况下索引其实是不生效的，比如索引列中存在 Null 值、重复数据较多的列、前导模糊查询不能利用索引（like '%XX' 或者 like '%XX%'）等。在一般情况下你可以使用执行计划查看索引是否真正生效
	- **联合索引不满足最左前缀原则**
	- 联合索引指一个索引会同时对应多个列，比如 c1、c2、c3 为三个字段，则可以通过 index_name(c1,c2,c3) 的方式建立联合索引，等于为 c1、(c1,c2)、(c1,c2,c3) 都建立了索引。因为每增加一个索引，也会增加写操作的磁盘开销，所以说联合索引是一种性价比比较高的建立索引的方式。
	- 最左前缀原则指在 c1、c2、c3 上建立了联合索引，索引中的数据也是按 c1、c2、c3 进行排序，最左前缀顾名思义就是最左边的优先。
	```sql
	SELECT * FROM table WHERE c1="1" AND c2="2" AND c3="3"
	```
	如果打破最左前缀规则联合索引是不生效的
	```sql
    SELECT * FROM table WHERE c1="1" AND c3="3"
    ```
	- 通过执行计划判断SQL有没有走索引或者索引有没有生效
	- 执行计划通常是开发者拿到慢 SQL 之后，优化 SQL 语句的第一步。MySQL 在解析 SQL 语句时，会生成多套执行方案，然后内部会进行一个成本的计算，通过优化器选择一个最优的方案执行，然后根据这个方案会生成一个执行计划。开发者通过查看 SQL 语句的执行计划，可以直观地了解到 MySQL 是如何解析执行这条 SQL 语句的，然后再针对性地进行优化。
	- 查看 SQL语句的执行计划：
	```sql
    desc select * from user
    ```
	或者添加 explain
	```sql
	mysql> explain select * from user;
	+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
	| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
	+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
	| 1  | SIMPLE      | user  | NULL       | ALL  | NULL          | NULL | NULL   | NULL | 9984 |  100.00 | NULL  |
	+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+
	1 row in set, 1 warning (0.01 sec)
	```
	1. table 显示的是这一行的数据是关于哪张表的，上述内容中显示的表名就是 user。
	2. type 这是重要的列，显示连接使用了何种类型，类型还是蛮多的，我选择最不理想的 ALL 类型和你解释一下，这个连接类型对于查询的表进行全表数据扫描，这种情况比较糟糕，应该尽量避免，上面的示例就进行了全表扫描。
	3. key 表示实际使用的索引。如果为 Null，则没有使用索引，这种情况也是尤其需要注意的。
	4. rows 表明 SQL 返回请求数据的行数，这一行非常重要，返回的内容中 SQL 遍历了 9984 行，其实也证明了这条 SQL 遍历了一张表。
	5. 关于 extra，我列举两个你需要注意的状态，因为这样的状态是会对性能产生不良的影响，意味着查询需要优化了。
		- Using filesort：表示SQL需要进行额外的步骤来发现如何对返回的行排序。它会根据连接类型、存储排序键值和匹配条件的全部行进行排序。
		- Using temporary：表示MySQL需要创建一个临时表来存储结果，非常消耗性能。
## 如何根治慢SQL
## 线上全链路性能测试实践总结